{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name : V Yaswanth Krishna --                           Roll No. : 17BT30025\n",
    "### Name : Juluri Shree Shiva Teja --                    Roll No. : 17EE10015\n",
    "### Name : Murali Karthik --                                     Roll No. : 17EE10012\n",
    "### Name : Sai Ram Tadiboyina --                           Roll No. : 17AG36017\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART1 : Sentence classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>Outer space is not friendly to life. Extreme t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Tennis, original name lawn tennis, game in whi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>One woman who frequently flew on Southwest was...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>In December 2019, almost seven years after the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>Any life-forms that somehow find themselves in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text Unnamed: 2  \\\n",
       "0   science  Outer space is not friendly to life. Extreme t...        NaN   \n",
       "1    sports  Tennis, original name lawn tennis, game in whi...        NaN   \n",
       "2  business  One woman who frequently flew on Southwest was...        NaN   \n",
       "3     covid  In December 2019, almost seven years after the...        NaN   \n",
       "4   science  Any life-forms that somehow find themselves in...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"traindata.csv\")\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>[outer, space, is, not, friendly, to, life., e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>[tennis,, original, name, lawn, tennis,, game,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>[one, woman, who, frequently, flew, on, southw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>[in, december, 2019,, almost, seven, years, af...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>[any, life-forms, that, somehow, find, themsel...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text Unnamed: 2  \\\n",
       "0   science  [outer, space, is, not, friendly, to, life., e...        NaN   \n",
       "1    sports  [tennis,, original, name, lawn, tennis,, game,...        NaN   \n",
       "2  business  [one, woman, who, frequently, flew, on, southw...        NaN   \n",
       "3     covid  [in, december, 2019,, almost, seven, years, af...        NaN   \n",
       "4   science  [any, life-forms, that, somehow, find, themsel...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#splitting the sentences into words and making them to lowercase\n",
    "df_train[\"text\"]= df_train[\"text\"].str.lower().str.split()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>[outer, space, friendly, life., extreme, tempe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>[tennis,, original, name, lawn, tennis,, game,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>[one, woman, frequently, flew, southwest, cons...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>[december, 2019,, almost, seven, years, mers, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>[life-forms, somehow, find, void, soon, die., ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text Unnamed: 2  \\\n",
       "0   science  [outer, space, friendly, life., extreme, tempe...        NaN   \n",
       "1    sports  [tennis,, original, name, lawn, tennis,, game,...        NaN   \n",
       "2  business  [one, woman, frequently, flew, southwest, cons...        NaN   \n",
       "3     covid  [december, 2019,, almost, seven, years, mers, ...        NaN   \n",
       "4   science  [life-forms, somehow, find, void, soon, die., ...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing the stopwords from the words present in the data\n",
    "df_train['text']=df_train['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>outer space friendly life. extreme temperature...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>tennis, original name lawn tennis, game two op...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>one woman frequently flew southwest constantly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>covid</td>\n",
       "      <td>december 2019, almost seven years mers 2012 ou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>life-forms somehow find void soon die. unless ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text Unnamed: 2  \\\n",
       "0   science  outer space friendly life. extreme temperature...        NaN   \n",
       "1    sports  tennis, original name lawn tennis, game two op...        NaN   \n",
       "2  business  one woman frequently flew southwest constantly...        NaN   \n",
       "3     covid  december 2019, almost seven years mers 2012 ou...        NaN   \n",
       "4   science  life-forms somehow find void soon die. unless ...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4 Unnamed: 5  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joining sentences to count the freq of words\n",
    "df_train[\"text\"]=df_train[\"text\"].str.join(\" \")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tennis</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>employees</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customers</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>flew</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>period</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>january</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>examples</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>first,</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         words  count\n",
       "0       tennis     12\n",
       "1     customer     11\n",
       "2      service     10\n",
       "3    employees      9\n",
       "4    customers      9\n",
       "..         ...    ...\n",
       "901       flew      1\n",
       "902     period      1\n",
       "903    january      1\n",
       "904   examples      1\n",
       "905     first,      1\n",
       "\n",
       "[906 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freq of occurence of words  with out stop words\n",
    "class_cond_dist = pd.DataFrame(df_train.text.str.split(expand=True).stack().value_counts())\n",
    "class_cond_dist.reset_index(level=0, inplace=True)\n",
    "class_cond_dist.columns = ['words', 'count']\n",
    "class_cond_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>count</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid</td>\n",
       "      <td>21</td>\n",
       "      <td>0.2625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>19</td>\n",
       "      <td>0.2375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels  count    prob\n",
       "0     covid     21  0.2625\n",
       "1    sports     20  0.2500\n",
       "2   science     20  0.2500\n",
       "3  business     19  0.2375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating the prior distribution of the labels:\n",
    "\n",
    "pd_labels = pd.DataFrame(df_train.category.str.split(expand=True).stack().value_counts())\n",
    "pd_labels.reset_index(level=0, inplace=True)\n",
    "pd_labels.columns = ['labels', 'count']\n",
    "\n",
    "prob=[]\n",
    "for i in range(4):\n",
    "    prob.append(pd_labels[\"count\"][i]/80)\n",
    "pd_labels[\"prob\"]=prob\n",
    "pd_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-0780cfda61bd>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label[cat][\"text\"]=label[cat][\"text\"].str.lower().str.split()  #splitting the sentences\n",
      "<ipython-input-10-0780cfda61bd>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label[cat][\"text\"]=label[cat][\"text\"].apply(lambda x: [word for word in x if word not in stop_words]) #removing stop wprds\n",
      "<ipython-input-10-0780cfda61bd>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  label[cat][\"text\"]=label[cat][\"text\"].str.join(\" \") # joining the words after removing stopwords\n"
     ]
    }
   ],
   "source": [
    "a = df_train.sort_values(by ='category', ascending = 1) \n",
    "label={'business':a[:19],'covid':a[19:40],'science':a[40:60],'sports':a[60:]}\n",
    "vocab={}\n",
    "for cat in label.keys():\n",
    "    label[cat][\"text\"]=label[cat][\"text\"].str.lower().str.split()  #splitting the sentences \n",
    "    label[cat][\"text\"]=label[cat][\"text\"].apply(lambda x: [word for word in x if word not in stop_words]) #removing stop wprds\n",
    "    label[cat][\"text\"]=label[cat][\"text\"].str.join(\" \") # joining the words after removing stopwords\n",
    "    \n",
    "    #calculating the freq of words in respective labels and building vocabulary:\n",
    "    \n",
    "    vocab[cat]=pd.DataFrame(label[cat].text.str.split(expand=True).stack().value_counts())\n",
    "    vocab[cat].reset_index(level=0, inplace=True)\n",
    "    vocab[cat].columns = ['word', 'count']\n",
    "    vocab[cat]=vocab[cat][vocab[cat]['count'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>P(word|label=business)</th>\n",
       "      <th>P(word|label=covid)</th>\n",
       "      <th>P(word|label=science)</th>\n",
       "      <th>P(word|label=sports)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tennis</td>\n",
       "      <td>12</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>customer</td>\n",
       "      <td>11</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>service</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>employees</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>customers</td>\n",
       "      <td>9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>flew</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>period</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>january</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>examples</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>first,</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>906 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         words  count  P(word|label=business)  P(word|label=covid)  \\\n",
       "0       tennis     12                   0.001                0.001   \n",
       "1     customer     11                   0.999                0.001   \n",
       "2      service     10                   0.300                0.001   \n",
       "3    employees      9                   0.999                0.001   \n",
       "4    customers      9                   0.999                0.001   \n",
       "..         ...    ...                     ...                  ...   \n",
       "901       flew      1                   0.999                0.001   \n",
       "902     period      1                   0.001                0.001   \n",
       "903    january      1                   0.001                0.999   \n",
       "904   examples      1                   0.999                0.001   \n",
       "905     first,      1                   0.999                0.001   \n",
       "\n",
       "     P(word|label=science)  P(word|label=sports)  \n",
       "0                    0.001                 0.999  \n",
       "1                    0.001                 0.001  \n",
       "2                    0.001                 0.700  \n",
       "3                    0.001                 0.001  \n",
       "4                    0.001                 0.001  \n",
       "..                     ...                   ...  \n",
       "901                  0.001                 0.001  \n",
       "902                  0.001                 0.999  \n",
       "903                  0.001                 0.001  \n",
       "904                  0.001                 0.001  \n",
       "905                  0.001                 0.001  \n",
       "\n",
       "[906 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding class conditional probabilities\n",
    "\n",
    "prob={}\n",
    "for cat in label.keys():   \n",
    "    prob[cat]=np.zeros(len(class_cond_dist)) \n",
    "    \n",
    "    for i in range(len(vocab[cat])):\n",
    "        for j in range(len(class_cond_dist)):\n",
    "            \n",
    "            if class_cond_dist['words'][j] == vocab[cat]['word'][i] :\n",
    "                \n",
    "                prob[cat][j]=vocab[cat]['count'][i]/class_cond_dist['count'][j]\n",
    "                \n",
    "                if prob[cat][j] == 1:\n",
    "                    prob[cat][j] = 0.999\n",
    "                    \n",
    "    for i in range(len(class_cond_dist)):\n",
    "        if prob[cat][i] == 0:\n",
    "            prob[cat][i] =0.001\n",
    "            \n",
    "    class_cond_dist= pd.concat([class_cond_dist, pd.Series(prob[cat], index=class_cond_dist.index, name='P(word|label='+cat+')')], axis=1)\n",
    "class_cond_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>[estimates, 1,000-micrometer, pellets, could, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>[“that’s, enough, time, potentially, get, mars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>[exactly, clumps, microbes, might, get, expell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science</td>\n",
       "      <td>[microbes, might, get, kicked, small, meteorit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>[someday,, microbial, life, ever, discovered, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0  science  [estimates, 1,000-micrometer, pellets, could, ...\n",
       "1  science  [“that’s, enough, time, potentially, get, mars...\n",
       "2  science  [exactly, clumps, microbes, might, get, expell...\n",
       "3  science  [microbes, might, get, kicked, small, meteorit...\n",
       "4  science  [someday,, microbial, life, ever, discovered, ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"testdata.csv\")\n",
    "df_test[\"text\"]= df_test[\"text\"].str.lower().str.split()\n",
    "df_test['text']=df_test['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>business</th>\n",
       "      <th>covid</th>\n",
       "      <th>science</th>\n",
       "      <th>sports</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science</td>\n",
       "      <td>[estimates, 1,000-micrometer, pellets, could, ...</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>1.750000e-13</td>\n",
       "      <td>8.715052e-02</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>science</td>\n",
       "      <td>[“that’s, enough, time, potentially, get, mars...</td>\n",
       "      <td>1.748250e-16</td>\n",
       "      <td>8.750000e-20</td>\n",
       "      <td>2.614516e-10</td>\n",
       "      <td>2.622375e-19</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science</td>\n",
       "      <td>[exactly, clumps, microbes, might, get, expell...</td>\n",
       "      <td>2.622375e-13</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>2.614516e-04</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science</td>\n",
       "      <td>[microbes, might, get, kicked, small, meteorit...</td>\n",
       "      <td>2.622375e-25</td>\n",
       "      <td>2.625000e-28</td>\n",
       "      <td>2.604073e-04</td>\n",
       "      <td>2.625000e-28</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>science</td>\n",
       "      <td>[someday,, microbial, life, ever, discovered, ...</td>\n",
       "      <td>2.625000e-07</td>\n",
       "      <td>2.625000e-07</td>\n",
       "      <td>2.619753e-01</td>\n",
       "      <td>2.625000e-07</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sports</td>\n",
       "      <td>[tennis,, service, correctly, returned,, playe...</td>\n",
       "      <td>8.859375e-33</td>\n",
       "      <td>1.312500e-38</td>\n",
       "      <td>1.312500e-38</td>\n",
       "      <td>1.365771e-05</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sports</td>\n",
       "      <td>[may, occur, tennis, player, fails, hit, ball,...</td>\n",
       "      <td>6.562500e-47</td>\n",
       "      <td>6.562500e-47</td>\n",
       "      <td>8.750000e-47</td>\n",
       "      <td>9.716546e-02</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sports</td>\n",
       "      <td>[win, game,, tennis, player, must, win, four, ...</td>\n",
       "      <td>2.625000e-25</td>\n",
       "      <td>2.625000e-25</td>\n",
       "      <td>2.622375e-22</td>\n",
       "      <td>2.606680e-04</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sports</td>\n",
       "      <td>[tennis,, never, satisfactorily, explained, th...</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>2.622375e-13</td>\n",
       "      <td>2.614516e-04</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sports</td>\n",
       "      <td>[tennis,, server’s, score, called, first;, thu...</td>\n",
       "      <td>2.910836e-20</td>\n",
       "      <td>2.625000e-31</td>\n",
       "      <td>2.625000e-31</td>\n",
       "      <td>1.159684e-07</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>business</td>\n",
       "      <td>[herb, kelleher, makes, clear, employees, come...</td>\n",
       "      <td>2.588488e-02</td>\n",
       "      <td>1.750000e-47</td>\n",
       "      <td>5.250000e-50</td>\n",
       "      <td>2.625000e-47</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>business</td>\n",
       "      <td>[don’t, carry, sorts, customers., write, say,,...</td>\n",
       "      <td>2.619753e-01</td>\n",
       "      <td>2.625000e-07</td>\n",
       "      <td>2.625000e-07</td>\n",
       "      <td>2.625000e-07</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>business</td>\n",
       "      <td>[continental, flight, attendant, offended, pas...</td>\n",
       "      <td>2.619753e-04</td>\n",
       "      <td>1.312500e-07</td>\n",
       "      <td>1.312500e-07</td>\n",
       "      <td>2.625000e-10</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>business</td>\n",
       "      <td>[pretty, offensive, stuff,, attendant, went, k...</td>\n",
       "      <td>2.622375e-01</td>\n",
       "      <td>2.625000e-04</td>\n",
       "      <td>2.625000e-04</td>\n",
       "      <td>2.625000e-04</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>business</td>\n",
       "      <td>[fact, customers, plain, wrong,, businesses, b...</td>\n",
       "      <td>7.781018e-02</td>\n",
       "      <td>2.625000e-40</td>\n",
       "      <td>2.625000e-40</td>\n",
       "      <td>1.837500e-37</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>covid</td>\n",
       "      <td>[virus, appeared, contained, within, china, cr...</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>2.617133e-07</td>\n",
       "      <td>2.625000e-16</td>\n",
       "      <td>2.619753e-10</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>covid</td>\n",
       "      <td>[however,, april, 2020,, 210, countries, terri...</td>\n",
       "      <td>8.750000e-20</td>\n",
       "      <td>8.706337e-02</td>\n",
       "      <td>1.312500e-19</td>\n",
       "      <td>2.625000e-22</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>covid</td>\n",
       "      <td>[similarly,, sars, mers, also, suspected, orig...</td>\n",
       "      <td>6.562500e-20</td>\n",
       "      <td>6.529753e-05</td>\n",
       "      <td>1.312500e-19</td>\n",
       "      <td>2.622375e-19</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>covid</td>\n",
       "      <td>[bats, known, harbor, coronaviruses, quite, ti...</td>\n",
       "      <td>3.493003e-29</td>\n",
       "      <td>3.482535e-20</td>\n",
       "      <td>5.239505e-32</td>\n",
       "      <td>5.239505e-32</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>covid</td>\n",
       "      <td>[identification, original, host, helps, us, co...</td>\n",
       "      <td>2.625000e-10</td>\n",
       "      <td>1.311188e-04</td>\n",
       "      <td>2.625000e-10</td>\n",
       "      <td>1.311188e-04</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                               text      business  \\\n",
       "0    science  [estimates, 1,000-micrometer, pellets, could, ...  2.625000e-16   \n",
       "1    science  [“that’s, enough, time, potentially, get, mars...  1.748250e-16   \n",
       "2    science  [exactly, clumps, microbes, might, get, expell...  2.622375e-13   \n",
       "3    science  [microbes, might, get, kicked, small, meteorit...  2.622375e-25   \n",
       "4    science  [someday,, microbial, life, ever, discovered, ...  2.625000e-07   \n",
       "5     sports  [tennis,, service, correctly, returned,, playe...  8.859375e-33   \n",
       "6     sports  [may, occur, tennis, player, fails, hit, ball,...  6.562500e-47   \n",
       "7     sports  [win, game,, tennis, player, must, win, four, ...  2.625000e-25   \n",
       "8     sports  [tennis,, never, satisfactorily, explained, th...  2.625000e-16   \n",
       "9     sports  [tennis,, server’s, score, called, first;, thu...  2.910836e-20   \n",
       "10  business  [herb, kelleher, makes, clear, employees, come...  2.588488e-02   \n",
       "11  business  [don’t, carry, sorts, customers., write, say,,...  2.619753e-01   \n",
       "12  business  [continental, flight, attendant, offended, pas...  2.619753e-04   \n",
       "13  business  [pretty, offensive, stuff,, attendant, went, k...  2.622375e-01   \n",
       "14  business  [fact, customers, plain, wrong,, businesses, b...  7.781018e-02   \n",
       "15     covid  [virus, appeared, contained, within, china, cr...  2.625000e-16   \n",
       "16     covid  [however,, april, 2020,, 210, countries, terri...  8.750000e-20   \n",
       "17     covid  [similarly,, sars, mers, also, suspected, orig...  6.562500e-20   \n",
       "18     covid  [bats, known, harbor, coronaviruses, quite, ti...  3.493003e-29   \n",
       "19     covid  [identification, original, host, helps, us, co...  2.625000e-10   \n",
       "\n",
       "           covid       science        sports Predicted  \n",
       "0   1.750000e-13  8.715052e-02  2.625000e-16   science  \n",
       "1   8.750000e-20  2.614516e-10  2.622375e-19   science  \n",
       "2   2.625000e-16  2.614516e-04  2.625000e-16   science  \n",
       "3   2.625000e-28  2.604073e-04  2.625000e-28   science  \n",
       "4   2.625000e-07  2.619753e-01  2.625000e-07   science  \n",
       "5   1.312500e-38  1.312500e-38  1.365771e-05    sports  \n",
       "6   6.562500e-47  8.750000e-47  9.716546e-02    sports  \n",
       "7   2.625000e-25  2.622375e-22  2.606680e-04    sports  \n",
       "8   2.625000e-16  2.622375e-13  2.614516e-04    sports  \n",
       "9   2.625000e-31  2.625000e-31  1.159684e-07    sports  \n",
       "10  1.750000e-47  5.250000e-50  2.625000e-47  business  \n",
       "11  2.625000e-07  2.625000e-07  2.625000e-07  business  \n",
       "12  1.312500e-07  1.312500e-07  2.625000e-10  business  \n",
       "13  2.625000e-04  2.625000e-04  2.625000e-04  business  \n",
       "14  2.625000e-40  2.625000e-40  1.837500e-37  business  \n",
       "15  2.617133e-07  2.625000e-16  2.619753e-10     covid  \n",
       "16  8.706337e-02  1.312500e-19  2.625000e-22     covid  \n",
       "17  6.529753e-05  1.312500e-19  2.622375e-19     covid  \n",
       "18  3.482535e-20  5.239505e-32  5.239505e-32     covid  \n",
       "19  1.311188e-04  2.625000e-10  1.311188e-04     covid  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#estimating the probabilities of every text into labels:\n",
    "\n",
    "prob_test={}\n",
    "for cat in label.keys(): \n",
    "    prob_test[cat]=np.zeros(len(df_test))\n",
    "    for i in range(len(df_test)):\n",
    "        prob_test[cat][i]=1\n",
    "        for j in range(len(df_test['text'][i])):\n",
    "            for k in range(len(class_cond_dist)):\n",
    "                if df_test['text'][i][j] == class_cond_dist[\"words\"][k]:\n",
    "                    prob_test[cat][i]=prob_test[cat][i]*class_cond_dist['P(word|label='+cat+')'][k]\n",
    "        prob_test[cat][i]=prob_test[cat][i]*pd_labels['prob'][0]\n",
    "\n",
    "    df_test = pd.concat([df_test, pd.Series(prob_test[cat], index=df_test.index, name=cat)], axis=1)\n",
    "\n",
    "#predicting the class of the given label based on prob values:\n",
    "\n",
    "df_test[\"Predicted\"]=df_test[[\"business\",\"covid\",\"science\",\"sports\"]].idxmax(axis=1)\n",
    "    \n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART2 : Sentence Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['In', 'the', 'midst', 'of', 'the', 'COVID-19', 'pandemic,', 'eating', 'healthy', 'food', 'remains', 'an', 'important', 'part', 'of', 'maintaining', 'your', 'health.'], ['While', 'there', 'are', 'no', 'specific', 'foods', 'that', 'can', 'help', 'protect', 'you', 'from', 'the', 'virus,', 'a', 'nutritious', 'diet', 'can', 'boost', 'your', 'immune', 'system', 'or', 'help', 'you', 'fight', 'off', 'symptoms.'], ['You', 'may', 'not', 'be', 'able', 'to', 'share', 'meals', 'with', 'friends', 'and', 'loved', 'ones,', 'but', 'there', 'are', 'lots', 'of', 'other', 'ways', 'to', 'eat', 'well', 'and', 'support', 'your', 'health', 'at', 'this', 'difficult', 'time.'], ['Eating', 'a', 'healthy', 'diet', 'is', 'not', 'about', 'strict', 'limitations,', 'staying', 'unrealistically', 'thin,', 'or', 'depriving', 'yourself', 'of', 'the', 'foods', 'you', 'love.', 'Rather,', 'it’s', 'about', 'feeling', 'great,', 'having', 'more', 'energy,', 'improving', 'your', 'health,', 'and', 'boosting', 'your', 'mood.'], ['Healthy', 'eating', 'doesn’t', 'have', 'to', 'be', 'overly', 'complicated.', 'If', 'you', 'feel', 'overwhelmed', 'by', 'all', 'the', 'conflicting', 'nutrition', 'and', 'diet', 'advice', 'out', 'there,', 'you’re', 'not', 'alone.']]\n"
     ]
    }
   ],
   "source": [
    "#Loading the data and splitting it into words\n",
    "\n",
    "df = pd.read_csv(\"40.csv\")\n",
    "vocab=[]\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "    vocab.append(df['text'][i].split())\n",
    "print(vocab[0:5])    \n",
    "#print(len(vocab))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['in', 'the', 'midst', 'of', 'the', 'covid19', 'pandemic', 'eating', 'healthy', 'food', 'remains', 'an', 'important', 'part', 'of', 'maintaining', 'your', 'health'], ['while', 'there', 'are', 'no', 'specific', 'foods', 'that', 'can', 'help', 'protect', 'you', 'from', 'the', 'virus', 'a', 'nutritious', 'diet', 'can', 'boost', 'your', 'immune', 'system', 'or', 'help', 'you', 'fight', 'off', 'symptoms'], ['you', 'may', 'not', 'be', 'able', 'to', 'share', 'meals', 'with', 'friends', 'and', 'loved', 'ones', 'but', 'there', 'are', 'lots', 'of', 'other', 'ways', 'to', 'eat', 'well', 'and', 'support', 'your', 'health', 'at', 'this', 'difficult', 'time'], ['eating', 'a', 'healthy', 'diet', 'is', 'not', 'about', 'strict', 'limitations', 'staying', 'unrealistically', 'thin', 'or', 'depriving', 'yourself', 'of', 'the', 'foods', 'you', 'love', 'rather', 'it’s', 'about', 'feeling', 'great', 'having', 'more', 'energy', 'improving', 'your', 'health', 'and', 'boosting', 'your', 'mood'], ['healthy', 'eating', 'doesn’t', 'have', 'to', 'be', 'overly', 'complicated', 'if', 'you', 'feel', 'overwhelmed', 'by', 'all', 'the', 'conflicting', 'nutrition', 'and', 'diet', 'advice', 'out', 'there', 'you’re', 'not', 'alone']]\n"
     ]
    }
   ],
   "source": [
    "#Removing the punctuation marks in the sentences\n",
    "\n",
    "temp=str.maketrans('','',string.punctuation)\n",
    "stripped_vocab=[]\n",
    "for sentence in vocab:\n",
    "    stripped_vocab.append([word.translate(temp).lower() for word in sentence])\n",
    "print(stripped_vocab[0:5])\n",
    "\n",
    "#print(len(stripped_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['midst', 'covid19', 'pandemic', 'eating', 'healthy', 'food', 'remains', 'important', 'part', 'maintaining', 'health'], ['specific', 'foods', 'help', 'protect', 'virus', 'nutritious', 'diet', 'boost', 'immune', 'system', 'help', 'fight', 'symptoms'], ['may', 'able', 'share', 'meals', 'friends', 'loved', 'ones', 'lots', 'ways', 'eat', 'well', 'support', 'health', 'difficult', 'time'], ['eating', 'healthy', 'diet', 'strict', 'limitations', 'staying', 'unrealistically', 'thin', 'depriving', 'foods', 'love', 'rather', 'it’s', 'feeling', 'great', 'energy', 'improving', 'health', 'boosting', 'mood'], ['healthy', 'eating', 'doesn’t', 'overly', 'complicated', 'feel', 'overwhelmed', 'conflicting', 'nutrition', 'diet', 'advice', 'you’re', 'alone']]\n"
     ]
    }
   ],
   "source": [
    "#Removing stop words from sentences\n",
    "\n",
    "stopWords=stopwords.words('english')\n",
    "\n",
    "filtered_vocab=[]\n",
    "for sentence in stripped_vocab:\n",
    "    filtered_vocab.append([word for word in sentence if word not in stopWords])\n",
    "print(filtered_vocab[0:5])        \n",
    "#print(len(filtered_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['midst', 'covid19', 'pandemic', 'eating', 'healthy', 'food', 'remains', 'important', 'part', 'maintaining', 'health'], ['specific', 'foods', 'help', 'protect', 'virus', 'nutritious', 'diet', 'boost', 'immune', 'system', 'help', 'fight', 'symptoms'], ['may', 'able', 'share', 'meals', 'friends', 'loved', 'ones', 'lots', 'ways', 'eat', 'well', 'support', 'health', 'difficult', 'time'], ['eating', 'healthy', 'diet', 'strict', 'limitations', 'staying', 'unrealistically', 'thin', 'depriving', 'foods', 'love', 'rather', 'it’s', 'feeling', 'great', 'energy', 'improving', 'health', 'boosting', 'mood'], ['healthy', 'eating', 'doesn’t', 'overly', 'complicated', 'feel', 'overwhelmed', 'conflicting', 'nutrition', 'diet', 'advice', 'you’re', 'alone']]\n"
     ]
    }
   ],
   "source": [
    "#As it observed that some words of type 'A—B' are not splitted into A and B, they are splitted manually\n",
    "\n",
    "vocabulary=[]\n",
    "for sentence in filtered_vocab:\n",
    "    sent=[]\n",
    "    for word in sentence:\n",
    "        sent+=word.split('—')\n",
    "    vocabulary.append(sent)\n",
    "print(vocabulary[0:5])\n",
    "\n",
    "#print(len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in vocabulary = 587\n",
      "Total number of distinct words in vocabulary = 382\n",
      "Prior probabilities sum = 1.0000000000000007\n"
     ]
    }
   ],
   "source": [
    "#Estimating prior probabilities\n",
    "\n",
    "prior_prob={}\n",
    "total_words_count=0\n",
    "sum=0\n",
    "for sentence in vocabulary:\n",
    "    for word in sentence:\n",
    "        if word in prior_prob.keys():\n",
    "            prior_prob[word]+=1\n",
    "            total_words_count+=1\n",
    "        else: \n",
    "            prior_prob[word]=1\n",
    "            total_words_count+=1\n",
    "for key in prior_prob.keys():\n",
    "    prior_prob[key]/=total_words_count\n",
    "    sum+=prior_prob[key]\n",
    "\n",
    "#print(prior_prob)    \n",
    "print(\"Total number of words in vocabulary =\",total_words_count)\n",
    "print(\"Total number of distinct words in vocabulary =\",len(prior_prob))\n",
    "print(\"Prior probabilities sum =\",sum)\n",
    "\n",
    "#print(len(prior_prob.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dataframe for posterior probabilities\n",
    "\n",
    "a = np.zeros(shape=(len(prior_prob),len(prior_prob)))\n",
    "posterior_prob = pd.DataFrame(a,columns=list(prior_prob.keys()))\n",
    "posterior_prob['y']=list(prior_prob.keys())\n",
    "posterior_prob.set_index('y',inplace=True)\n",
    "\n",
    "#posterior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>midst</th>\n",
       "      <th>covid19</th>\n",
       "      <th>pandemic</th>\n",
       "      <th>eating</th>\n",
       "      <th>healthy</th>\n",
       "      <th>food</th>\n",
       "      <th>remains</th>\n",
       "      <th>important</th>\n",
       "      <th>part</th>\n",
       "      <th>maintaining</th>\n",
       "      <th>...</th>\n",
       "      <th>onion</th>\n",
       "      <th>plain</th>\n",
       "      <th>salads</th>\n",
       "      <th>steamed</th>\n",
       "      <th>veggies</th>\n",
       "      <th>quickly</th>\n",
       "      <th>bland</th>\n",
       "      <th>taste</th>\n",
       "      <th>vegetable</th>\n",
       "      <th>dishes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>midst</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid19</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandemic</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eating</th>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>3.333333e-01</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>8.333333e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthy</th>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>2.857143e-01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>2.142857e-01</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>7.142857e-02</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickly</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bland</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taste</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vegetable</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dishes</th>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  midst       covid19      pandemic        eating  \\\n",
       "y                                                                   \n",
       "midst      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "covid19    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "pandemic   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "eating     8.333333e-02  8.333333e-02  8.333333e-02  1.000000e+00   \n",
       "healthy    7.142857e-02  7.142857e-02  7.142857e-02  2.857143e-01   \n",
       "...                 ...           ...           ...           ...   \n",
       "quickly    1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "bland      1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "taste      1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "vegetable  1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "dishes     1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "\n",
       "                healthy          food       remains     important  \\\n",
       "y                                                                   \n",
       "midst      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "covid19    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "pandemic   1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "eating     3.333333e-01  3.333333e-01  8.333333e-02  8.333333e-02   \n",
       "healthy    1.000000e+00  1.428571e-01  7.142857e-02  2.142857e-01   \n",
       "...                 ...           ...           ...           ...   \n",
       "quickly    1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "bland      1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "taste      1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "vegetable  1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "dishes     1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "\n",
       "                   part   maintaining  ...         onion         plain  \\\n",
       "y                                      ...                               \n",
       "midst      1.000000e+00  1.000000e+00  ...  1.000000e-08  1.000000e-08   \n",
       "covid19    1.000000e+00  1.000000e+00  ...  1.000000e-08  1.000000e-08   \n",
       "pandemic   1.000000e+00  1.000000e+00  ...  1.000000e-08  1.000000e-08   \n",
       "eating     8.333333e-02  8.333333e-02  ...  1.000000e-08  1.000000e-08   \n",
       "healthy    7.142857e-02  7.142857e-02  ...  7.142857e-02  1.000000e-08   \n",
       "...                 ...           ...  ...           ...           ...   \n",
       "quickly    1.000000e-08  1.000000e-08  ...  1.000000e-08  1.000000e+00   \n",
       "bland      1.000000e-08  1.000000e-08  ...  1.000000e-08  1.000000e+00   \n",
       "taste      1.000000e-08  1.000000e-08  ...  1.000000e-08  1.000000e+00   \n",
       "vegetable  1.000000e-08  1.000000e-08  ...  1.000000e-08  1.000000e+00   \n",
       "dishes     1.000000e-08  1.000000e-08  ...  1.000000e-08  1.000000e+00   \n",
       "\n",
       "                 salads       steamed       veggies       quickly  \\\n",
       "y                                                                   \n",
       "midst      1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "covid19    1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "pandemic   1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "eating     1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "healthy    1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08   \n",
       "...                 ...           ...           ...           ...   \n",
       "quickly    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "bland      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "taste      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "vegetable  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "dishes     1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "\n",
       "                  bland         taste     vegetable        dishes  \n",
       "y                                                                  \n",
       "midst      1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08  \n",
       "covid19    1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08  \n",
       "pandemic   1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08  \n",
       "eating     1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08  \n",
       "healthy    1.000000e-08  1.000000e-08  1.000000e-08  1.000000e-08  \n",
       "...                 ...           ...           ...           ...  \n",
       "quickly    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "bland      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "taste      1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "vegetable  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "dishes     1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  \n",
       "\n",
       "[382 rows x 382 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating posterior probabilities\n",
    "#p[word][y] denotes the P(word|y)=Probability of word given y\n",
    "\n",
    "for y in list(prior_prob.keys()):\n",
    "    sentence_count=0\n",
    " \n",
    "    for sentence in vocabulary:\n",
    "        if y in sentence:\n",
    "            sentence_count+=1\n",
    "            for word in set(sentence):\n",
    "                posterior_prob[word][y]+=1\n",
    "    for word in list(prior_prob.keys()):\n",
    "        posterior_prob[word][y]=posterior_prob[word][y]/sentence_count\n",
    "\n",
    "#Replacing 0 with 1e-8        \n",
    "\n",
    "posterior_prob=posterior_prob.replace(0,1e-8)    \n",
    "posterior_prob    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Eating', 'healthy', 'food', 'is', 'important', 'for', 'maintaining', 'good', '_____'], ['Following', 'a', 'healthy', 'diet', 'will', 'boost', 'your', '_____'], ['Avoid', 'eating', 'chemical', 'additives,', 'added', 'sugars', 'in', 'your', 'diet.', 'Switch', 'to', 'a', 'healthy', '____'], ['Your', 'diet', 'should', 'be', 'rich', 'of', 'vitamins', 'D,K,', 'calcium', 'and', '______'], ['The', 'healthier', 'the', 'food', 'you', 'eat,', 'the', 'better', 'you’ll', 'feel', 'after', 'a', '_____.'], ['Dehydration', 'causes', 'tiredness,', 'low', 'energy', 'and', 'head', 'aches.', 'Drink', 'plenty', 'of', '______'], ['People', 'with', 'kidney', 'disease', 'should', 'avoid', 'eating', 'high', 'amounts', 'of', '______'], ['We', 'should', 'avoid', 'eating', 'transfats.', 'Eating', 'healthy', 'fats', 'and', 'dietary', 'fibre', 'can', 'help', 'us', 'lose', '____'], ['Mindless', 'eating', 'is', 'often', 'caused', 'by', 'eating', 'alone.', 'We', 'should', 'avoid', 'eating', 'while', 'we', 'are', 'in', 'front', 'of', 'a', 'TV', 'or', 'a', '______'], ['Eating', 'more', 'junk', 'food', 'will', 'make', 'you', 'feel', 'uncomfortable', 'and', '_____']]\n",
      "[['eating', 'healthy', 'food', 'is', 'important', 'for', 'maintaining', 'good', ''], ['following', 'a', 'healthy', 'diet', 'will', 'boost', 'your', ''], ['avoid', 'eating', 'chemical', 'additives', 'added', 'sugars', 'in', 'your', 'diet', 'switch', 'to', 'a', 'healthy', ''], ['your', 'diet', 'should', 'be', 'rich', 'of', 'vitamins', 'dk', 'calcium', 'and', ''], ['the', 'healthier', 'the', 'food', 'you', 'eat', 'the', 'better', 'you’ll', 'feel', 'after', 'a', ''], ['dehydration', 'causes', 'tiredness', 'low', 'energy', 'and', 'head', 'aches', 'drink', 'plenty', 'of', ''], ['people', 'with', 'kidney', 'disease', 'should', 'avoid', 'eating', 'high', 'amounts', 'of', ''], ['we', 'should', 'avoid', 'eating', 'transfats', 'eating', 'healthy', 'fats', 'and', 'dietary', 'fibre', 'can', 'help', 'us', 'lose', ''], ['mindless', 'eating', 'is', 'often', 'caused', 'by', 'eating', 'alone', 'we', 'should', 'avoid', 'eating', 'while', 'we', 'are', 'in', 'front', 'of', 'a', 'tv', 'or', 'a', ''], ['eating', 'more', 'junk', 'food', 'will', 'make', 'you', 'feel', 'uncomfortable', 'and', '']]\n",
      "[['eating', 'healthy', 'food', 'important', 'maintaining', 'good'], ['following', 'healthy', 'diet', 'boost'], ['avoid', 'eating', 'chemical', 'additives', 'added', 'sugars', 'diet', 'switch', 'healthy'], ['diet', 'rich', 'vitamins', 'dk', 'calcium'], ['healthier', 'food', 'eat', 'better', 'you’ll', 'feel'], ['dehydration', 'causes', 'tiredness', 'low', 'energy', 'head', 'aches', 'drink', 'plenty'], ['people', 'kidney', 'disease', 'avoid', 'eating', 'high', 'amounts'], ['avoid', 'eating', 'transfats', 'eating', 'healthy', 'fats', 'dietary', 'fibre', 'help', 'us', 'lose'], ['mindless', 'eating', 'often', 'caused', 'eating', 'alone', 'avoid', 'eating', 'front', 'tv'], ['eating', 'junk', 'food', 'make', 'feel', 'uncomfortable']]\n"
     ]
    }
   ],
   "source": [
    "#Loading the test dataset and refining the text with split, removing punctuation,removing stop words\n",
    "\n",
    "df = pd.read_csv(\"10.csv\")\n",
    "test_vocab=[]\n",
    "for i in range(df.shape[0]):\n",
    "    test_vocab.append(df['text'][i].split())\n",
    "print(test_vocab)    \n",
    "#print(len(test_vocab))    \n",
    "\n",
    "\n",
    "\n",
    "temp=str.maketrans('','',string.punctuation)\n",
    "stripped_test_vocab=[]\n",
    "for sentence in test_vocab:\n",
    "    stripped_test_vocab.append([word.translate(temp).lower() for word in sentence])\n",
    "print(stripped_test_vocab)\n",
    "\n",
    "#print(len(stripped_test_vocab))\n",
    "\n",
    "\n",
    "filtered_test_vocab=[]\n",
    "for sentence in stripped_test_vocab:\n",
    "    filtered_test_vocab.append([word for word in sentence if word not in stopWords+['']])\n",
    "print(filtered_test_vocab)        \n",
    "#print(len(filtered_test_vocab))\n",
    "\n",
    "\n",
    "test_vocabulary=filtered_test_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe for posterior probabilities on test dataset\n",
    "\n",
    "a = np.zeros(shape=(len(prior_prob),len(test_vocabulary)))\n",
    "test_posterior_prob = pd.DataFrame(a,columns=[i for i in range(len(test_vocabulary))])\n",
    "test_posterior_prob['y']=list(prior_prob.keys())\n",
    "test_posterior_prob.set_index('y',inplace=True)\n",
    "\n",
    "#test_posterior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eating healthy food is important for maintaining good _____ midst  with probability 0.1589296951841983\n",
      "Following a healthy diet will boost your _____ diet  with probability 0.18335329356299687\n",
      "Avoid eating chemical additives, added sugars in your diet. Switch to a healthy ____ feeling  with probability 0.9651884585810944\n",
      "Your diet should be rich of vitamins D,K, calcium and ______ calcium  with probability 0.11492990552613866\n",
      "The healthier the food you eat, the better you’ll feel after a _____. better  with probability 0.2606071168546024\n",
      "Dehydration causes tiredness, low energy and head aches. Drink plenty of ______ water  with probability 0.1299761183925986\n",
      "People with kidney disease should avoid eating high amounts of ______ disease  with probability 0.9999999785253613\n",
      "We should avoid eating transfats. Eating healthy fats and dietary fibre can help us lose ____ foods  with probability 0.9999999999997894\n",
      "Mindless eating is often caused by eating alone. We should avoid eating while we are in front of a TV or a ______ front  with probability 0.1903235083554125\n",
      "Eating more junk food will make you feel uncomfortable and _____ food  with probability 0.9999998295177301\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>midst</th>\n",
       "      <td>1.589297e-01</td>\n",
       "      <td>1.389040e-17</td>\n",
       "      <td>6.177206e-39</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-40</td>\n",
       "      <td>6.498806e-42</td>\n",
       "      <td>8.000000e-32</td>\n",
       "      <td>1.195742e-43</td>\n",
       "      <td>1.903235e-41</td>\n",
       "      <td>4.095999e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid19</th>\n",
       "      <td>1.589297e-01</td>\n",
       "      <td>1.389040e-17</td>\n",
       "      <td>6.177206e-39</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-40</td>\n",
       "      <td>6.498806e-42</td>\n",
       "      <td>8.000000e-32</td>\n",
       "      <td>1.195742e-43</td>\n",
       "      <td>1.903235e-41</td>\n",
       "      <td>4.095999e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pandemic</th>\n",
       "      <td>1.589297e-01</td>\n",
       "      <td>1.389040e-17</td>\n",
       "      <td>6.177206e-39</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-40</td>\n",
       "      <td>6.498806e-42</td>\n",
       "      <td>8.000000e-32</td>\n",
       "      <td>1.195742e-43</td>\n",
       "      <td>1.903235e-41</td>\n",
       "      <td>4.095999e-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eating</th>\n",
       "      <td>1.471571e-03</td>\n",
       "      <td>9.260267e-10</td>\n",
       "      <td>4.118137e-31</td>\n",
       "      <td>1.532399e-17</td>\n",
       "      <td>4.826058e-19</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>6.666667e-17</td>\n",
       "      <td>1.383961e-14</td>\n",
       "      <td>1.835682e-05</td>\n",
       "      <td>1.365333e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthy</th>\n",
       "      <td>1.390056e-03</td>\n",
       "      <td>5.953029e-02</td>\n",
       "      <td>1.058950e-30</td>\n",
       "      <td>3.283712e-10</td>\n",
       "      <td>2.978367e-33</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>2.285714e-24</td>\n",
       "      <td>7.320871e-29</td>\n",
       "      <td>3.884153e-27</td>\n",
       "      <td>1.194169e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickly</th>\n",
       "      <td>1.589297e-41</td>\n",
       "      <td>1.389040e-25</td>\n",
       "      <td>6.177206e-55</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-48</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>8.000000e-40</td>\n",
       "      <td>1.195742e-59</td>\n",
       "      <td>1.903235e-49</td>\n",
       "      <td>4.095999e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bland</th>\n",
       "      <td>1.589297e-41</td>\n",
       "      <td>1.389040e-25</td>\n",
       "      <td>6.177206e-55</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-48</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>8.000000e-40</td>\n",
       "      <td>1.195742e-59</td>\n",
       "      <td>1.903235e-49</td>\n",
       "      <td>4.095999e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taste</th>\n",
       "      <td>1.589297e-41</td>\n",
       "      <td>1.389040e-25</td>\n",
       "      <td>6.177206e-55</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-48</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>8.000000e-40</td>\n",
       "      <td>1.195742e-59</td>\n",
       "      <td>1.903235e-49</td>\n",
       "      <td>4.095999e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vegetable</th>\n",
       "      <td>1.589297e-41</td>\n",
       "      <td>1.389040e-25</td>\n",
       "      <td>6.177206e-55</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-48</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>8.000000e-40</td>\n",
       "      <td>1.195742e-59</td>\n",
       "      <td>1.903235e-49</td>\n",
       "      <td>4.095999e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dishes</th>\n",
       "      <td>1.589297e-41</td>\n",
       "      <td>1.389040e-25</td>\n",
       "      <td>6.177206e-55</td>\n",
       "      <td>7.661994e-26</td>\n",
       "      <td>2.084857e-48</td>\n",
       "      <td>6.498806e-34</td>\n",
       "      <td>8.000000e-40</td>\n",
       "      <td>1.195742e-59</td>\n",
       "      <td>1.903235e-49</td>\n",
       "      <td>4.095999e-46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1             2             3  \\\n",
       "y                                                                   \n",
       "midst      1.589297e-01  1.389040e-17  6.177206e-39  7.661994e-26   \n",
       "covid19    1.589297e-01  1.389040e-17  6.177206e-39  7.661994e-26   \n",
       "pandemic   1.589297e-01  1.389040e-17  6.177206e-39  7.661994e-26   \n",
       "eating     1.471571e-03  9.260267e-10  4.118137e-31  1.532399e-17   \n",
       "healthy    1.390056e-03  5.953029e-02  1.058950e-30  3.283712e-10   \n",
       "...                 ...           ...           ...           ...   \n",
       "quickly    1.589297e-41  1.389040e-25  6.177206e-55  7.661994e-26   \n",
       "bland      1.589297e-41  1.389040e-25  6.177206e-55  7.661994e-26   \n",
       "taste      1.589297e-41  1.389040e-25  6.177206e-55  7.661994e-26   \n",
       "vegetable  1.589297e-41  1.389040e-25  6.177206e-55  7.661994e-26   \n",
       "dishes     1.589297e-41  1.389040e-25  6.177206e-55  7.661994e-26   \n",
       "\n",
       "                      4             5             6             7  \\\n",
       "y                                                                   \n",
       "midst      2.084857e-40  6.498806e-42  8.000000e-32  1.195742e-43   \n",
       "covid19    2.084857e-40  6.498806e-42  8.000000e-32  1.195742e-43   \n",
       "pandemic   2.084857e-40  6.498806e-42  8.000000e-32  1.195742e-43   \n",
       "eating     4.826058e-19  6.498806e-34  6.666667e-17  1.383961e-14   \n",
       "healthy    2.978367e-33  6.498806e-34  2.285714e-24  7.320871e-29   \n",
       "...                 ...           ...           ...           ...   \n",
       "quickly    2.084857e-48  6.498806e-34  8.000000e-40  1.195742e-59   \n",
       "bland      2.084857e-48  6.498806e-34  8.000000e-40  1.195742e-59   \n",
       "taste      2.084857e-48  6.498806e-34  8.000000e-40  1.195742e-59   \n",
       "vegetable  2.084857e-48  6.498806e-34  8.000000e-40  1.195742e-59   \n",
       "dishes     2.084857e-48  6.498806e-34  8.000000e-40  1.195742e-59   \n",
       "\n",
       "                      8             9  \n",
       "y                                      \n",
       "midst      1.903235e-41  4.095999e-30  \n",
       "covid19    1.903235e-41  4.095999e-30  \n",
       "pandemic   1.903235e-41  4.095999e-30  \n",
       "eating     1.835682e-05  1.365333e-22  \n",
       "healthy    3.884153e-27  1.194169e-16  \n",
       "...                 ...           ...  \n",
       "quickly    1.903235e-49  4.095999e-46  \n",
       "bland      1.903235e-49  4.095999e-46  \n",
       "taste      1.903235e-49  4.095999e-46  \n",
       "vegetable  1.903235e-49  4.095999e-46  \n",
       "dishes     1.903235e-49  4.095999e-46  \n",
       "\n",
       "[382 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating posterior probabilities on test dataset and predicting the last word along with their probability \n",
    "\n",
    "for i in range(len(test_vocabulary)):\n",
    "    sentence=test_vocabulary[i]\n",
    "    for y in list(prior_prob.keys()):\n",
    "        test_posterior_prob[i][y]=prior_prob[y]\n",
    "        for word in set(sentence):\n",
    "            if word in list(prior_prob.keys()):\n",
    "                test_posterior_prob[i][y]*=posterior_prob[word][y]\n",
    "    col_sum=test_posterior_prob[i].sum()    \n",
    "    test_posterior_prob[i]/=col_sum\n",
    "    print(df['text'][i],test_posterior_prob[i].idxmax(),\" with probability\",test_posterior_prob[i].max())\n",
    "test_posterior_prob            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
